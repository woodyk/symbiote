#!/usr/bin/env python3
# -*- coding: utf-8 -*-
#
# File: ImageQuestionAnswer.py
# Author: Wadih Khairallah
# Description: 
# Created: 2024-11-27 06:40:29
#!/usr/bin/env python3
#
# ImageQuestionAnswer.py


import requests
from PIL import Image
from transformers import BlipProcessor, BlipForQuestionAnswering
import warnings

# Suppress all FutureWarning globally
warnings.filterwarnings("ignore")

class ImageVQA:
    def __init__(self, image_path_or_url, model_name="Salesforce/blip-vqa-base"):
        # Initialize the processor and model
        self.processor = BlipProcessor.from_pretrained("Salesforce/blip-vqa-base", force_download=False)
        self.model = BlipForQuestionAnswering.from_pretrained("Salesforce/blip-vqa-base", force_download=False)
        self.model = self.model.to('cpu')  # Ensure the model runs on CPU
        
        # Load the image upon initialization
        self.image = self._load_image(image_path_or_url)

    def _load_image(self, image_path_or_url):
        try:
            if image_path_or_url.startswith('http://') or image_path_or_url.startswith('https://'):
                response = requests.get(image_path_or_url, stream=True)
                image = Image.open(response.raw).convert('RGB')
            else:
                image = Image.open(image_path_or_url).convert('RGB')
            return image
        except Exception as e:
            raise Exception(f"Failed to load image: {e}")

    def ask_question(self, question):
        """
        Asks a question about the loaded image.
        
        Parameters:
            question (str): The question to ask about the image.
        
        Returns:
            str: The answer generated by the model.
        """
        inputs = self.processor(self.image, question, return_tensors="pt")
        out = self.model.generate(**inputs)
        answer = self.processor.decode(out[0], skip_special_tokens=True)
        return answer

if __name__ == "__main__":
    # Initialize the class with an image (from a path or URL)
    image_vqa = ImageVQA("https://storage.googleapis.com/sfr-vision-language-research/BLIP/demo.jpg")

    # Ask questions about the image
    answer_1 = image_vqa.ask_question("How many dogs are in the picture?")
    print("Answer 1:", answer_1)

    answer_2 = image_vqa.ask_question("What color is the car?")
    print("Answer 2:", answer_2)

